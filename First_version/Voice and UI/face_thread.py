# face_thread.py
import sys
import os
import cv2
import numpy as np
from PyQt5.QtCore import QThread, pyqtSignal, QTimer
from PyQt5.QtGui import QImage, QPixmap

# æ·»åŠ visual_interactionæ¨¡å—è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'visual_interaction'))

try:
    from inference import VisualRecognitionInterface
except ImportError as e:
    print(f"Warning: Cannot import VisualRecognitionInterface: {e}")
    VisualRecognitionInterface = None

import state


class FaceThread(QThread):
    # å®šä¹‰ä¿¡å·
    frame_ready = pyqtSignal(np.ndarray)  # å‘é€å¸§æ•°æ®
    distraction_detected = pyqtSignal(bool, int)  # åˆ†å¿ƒæ£€æµ‹ä¿¡å·
    gesture_detected = pyqtSignal(str)  # æ‰‹åŠ¿æ£€æµ‹ä¿¡å·
    gaze_data = pyqtSignal(dict)  # è§†çº¿æ•°æ®ä¿¡å·
    error_occurred = pyqtSignal(str)  # é”™è¯¯ä¿¡å·
    
    def __init__(self, parent=None, camera_index=0):
        super().__init__(parent)
        self.camera_index = camera_index
        self.cap = None
        self.running = False
        self.visual_interface = None
        self.frame_count = 0
    def init_camera(self):
        """åˆå§‹åŒ–æ‘„åƒå¤´"""
        try:
            self.cap = cv2.VideoCapture(self.camera_index)
            if not self.cap.isOpened():
                raise Exception(f"Cannot open camera {self.camera_index}")
            
            # è®¾ç½®æ‘„åƒå¤´å‚æ•°
            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            self.cap.set(cv2.CAP_PROP_FPS, 30)
            
            print(f"âœ“ æ‘„åƒå¤´åˆå§‹åŒ–æˆåŠŸ (ç´¢å¼•: {self.camera_index})")
            return True
        except Exception as e:
            print(f"âœ— æ‘„åƒå¤´åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            self.error_occurred.emit(f"Camera initialization failed: {str(e)}")
            return False
    
    def init_visual_recognition(self):
        """åˆå§‹åŒ–è§†è§‰è¯†åˆ«æ¨¡å—"""
        if VisualRecognitionInterface is None:
            self.error_occurred.emit("Visual recognition module not available")
            return False
            
        try:
            # è·å–æƒé‡æ–‡ä»¶è·¯å¾„
            weight_path = os.path.join(
                os.path.dirname(__file__), 
                '..', 
                'visual_interaction', 
                'weights', 
                '18.pt'
            )
            
            self.visual_interface = VisualRecognitionInterface(
                model_name="resnet18",
                weight_path=weight_path,
                dataset="mpiigaze"
            )            # è®¾ç½®å›è°ƒå‡½æ•°
            self.visual_interface.set_distraction_callback(self.on_distraction_detected)
            self.visual_interface.set_gesture_callback(self.on_gesture_detected)
            
            print("âœ“ è§†è§‰è¯†åˆ«ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
            print("  - è§†çº¿è¿½è¸ªæ¨¡å—å·²å¯åŠ¨")
            print("  - åˆ†å¿ƒæ£€æµ‹æ¨¡å—å·²å¯åŠ¨") 
            print("  - æ‰‹åŠ¿è¯†åˆ«æ¨¡å—å·²å¯åŠ¨")
            return True
        except Exception as e:
            self.error_occurred.emit(f"Visual recognition initialization failed: {str(e)}")
            return False
    
    def on_distraction_detected(self, distracted, warning_level):
        """åˆ†å¿ƒæ£€æµ‹å›è°ƒ"""
        state.is_warning = distracted
        self.distraction_detected.emit(distracted, warning_level)
        
    def on_gesture_detected(self, gesture):
        """æ‰‹åŠ¿æ£€æµ‹å›è°ƒ"""
        self.gesture_detected.emit(gesture)
    def start_recognition(self):
        """å¼€å§‹è¯†åˆ«"""
        print("ğŸš€ å¯åŠ¨è½¦è½½æ™ºèƒ½äº¤äº’ç³»ç»Ÿ...")
        if self.init_camera() and self.init_visual_recognition():
            self.running = True
            self.start()
            print("âœ“ ç³»ç»Ÿå¯åŠ¨å®Œæˆï¼Œå¼€å§‹ç›‘æ§...")
        else:
            print("âœ— ç³»ç»Ÿå¯åŠ¨å¤±è´¥")
            self.error_occurred.emit("Failed to initialize camera or visual recognition")
    
    def stop_recognition(self):
        """åœæ­¢è¯†åˆ«"""
        self.running = False
        if self.cap:
            self.cap.release()
        self.quit()
        self.wait()
    
    def run(self):
        """ä¸»è¿è¡Œå¾ªç¯"""
        if not self.cap or not self.visual_interface:
            return
            
        while self.running:
            ret, frame = self.cap.read()
            if not ret:
                continue
                
            try:
                # å¤„ç†å¸§
                result = self.visual_interface.process_frame(frame)
                
                # å‘é€å¸§æ•°æ®
                self.frame_ready.emit(frame)
                
                # å‘é€è§†çº¿æ•°æ®
                self.gaze_data.emit(result)
                
                self.frame_count += 1
                
                # æ§åˆ¶å¸§ç‡
                self.msleep(33)  # ~30 FPS
                
            except Exception as e:
                self.error_occurred.emit(f"Frame processing error: {str(e)}")
                
        if self.cap:
            self.cap.release()
